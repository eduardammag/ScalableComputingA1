#  Micro-Framework de Processamento Paralelo de Dados

Projeto desenvolvido para a disciplina de **Computa√ß√£o Escal√°vel**, com o objetivo de construir um pipeline modular e eficiente para ingest√£o, tratamento e carregamento de dados m√©dicos simulados. A estrutura do pipeline √© gen√©rica, com suporte √† execu√ß√£o paralela e personaliza√ß√£o por meio de triggers e tratadores.

---

##  Instala√ß√£o

Clone o reposit√≥rio e compile o projeto com `make`:

```bash
make

> Requisitos: `g++`, `make`, `sqlite3`, `Python 3.x`

---

## üìÅ Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ etl/                    # Componentes C++ do ETL (extrator, handler, loader)
‚îú‚îÄ‚îÄ pipeline/               # Estrutura do pipeline
‚îú‚îÄ‚îÄ simulator.py            # Gera√ß√£o de dados mock semanais
‚îú‚îÄ‚îÄ databases_mock/         # Arquivos gerados pelo mock
‚îú‚îÄ‚îÄ triggers.cpp            # Implementa√ß√£o dos disparadores do pipeline
‚îú‚îÄ‚îÄ main.cpp                # Entrada principal do pipeline
‚îú‚îÄ‚îÄ Makefile                # Build do projeto
‚îú‚îÄ‚îÄ simulator_state.json    # Armazena os dados processados

```

---

##  Como Executar

1. Gerar os dados da semana atual com o script em Python:

```bash
python3 simulator.py
```

2. Compilar e executar o pipeline:

```bash
make
./programa
```

> A cada execu√ß√£o do mock, ser√° gerada uma nova semana de dados com base na semana anterior. O controle √© feito automaticamente pelo arquivo `simulator_state.json`.

---

## üìä Fontes de Dados Simulados

O mock em Python gera tr√™s tipos de dados:

- **OMS** (`oms_mock.txt`)  
  Arquivo `.txt` tabulado com dados agregados por ilha: √≥bitos, popula√ß√£o, recuperados, vacinados, data.

- **Hospitais** (`hospital_mock_*.csv`)  
  Arquivos `.csv` com registros de pacientes por hospital, incluindo idade, sintomas, sexo, interna√ß√£o, CEP e data.

- **Secretaria de Sa√∫de** (`secretary_data.db`)  
  Banco SQLite com a tabela `pacientes`, contendo diagn√≥stico, vacina√ß√£o, escolaridade, popula√ß√£o e data.

---

##  Arquitetura do Pipeline

- **Trigger**: ativa o pipeline por tempo ou requisi√ß√£o.
- **Extrator**: detecta e l√™ arquivos `.txt`, `.csv`, ou `.db`, padronizando em `DataFrame`.
- **Tratadores gerais**: filtram inv√°lidos, removem linhas e colunas.
- **Tratadores espec√≠ficos**: agregam por colunas, calculam m√©dias, concatenam dataframes.
- **Loader**: armazena os dados tratados.
- **Display**: relat√≥rio semanal da doen√ßa para visualiza√ß√£o de resultados.

---

##  Paralelismo

O pipeline implementa a l√≥gica Produtor-Consumidor com:

- Fila de arquivos protegida por `mutex`
- V√°rias threads de extra√ß√£o executando em paralelo
- Comunica√ß√£o por `condition_variable` entre etapas

O n√∫mero de threads pode ser ajustado na chamada da fun√ß√£o `executarPipeline`.

---



## Alunas

- Ana J√∫lia Amaro Pereira Rocha  
- Maria Eduarda Mesquita Magalh√£es  
- Mariana Fernandes Rocha  
- Paula Eduarda de Lima  

**Curso**: Ci√™ncia de Dados e Intelig√™ncia Artificial ‚Äì FGV EMAp

---
